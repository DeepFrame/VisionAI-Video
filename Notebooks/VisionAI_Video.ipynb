{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO/cSA1fvd82M66xoD3nxbr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeepFrame/VisionAI-Video/blob/main/VisionAI_Video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Dependencies"
      ],
      "metadata": {
        "id": "wEXWnEdBrxzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install retina-face"
      ],
      "metadata": {
        "id": "bJp4P5nirwpi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3976e81e-db54-4290-f091-37242d959d4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting retina-face\n",
            "  Downloading retina_face-0.0.17-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from retina-face) (2.0.2)\n",
            "Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from retina-face) (5.2.0)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.12/dist-packages (from retina-face) (11.3.0)\n",
            "Requirement already satisfied: opencv-python>=3.4.4 in /usr/local/lib/python3.12/dist-packages (from retina-face) (4.12.0.88)\n",
            "Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from retina-face) (2.19.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown>=3.10.1->retina-face) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown>=3.10.1->retina-face) (3.19.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown>=3.10.1->retina-face) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown>=3.10.1->retina-face) (4.67.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (5.29.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (1.75.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->retina-face) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=1.9.0->retina-face) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=1.9.0->retina-face) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=1.9.0->retina-face) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown>=3.10.1->retina-face) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown>=3.10.1->retina-face) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown>=3.10.1->retina-face) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown>=3.10.1->retina-face) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=1.9.0->retina-face) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=1.9.0->retina-face) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=1.9.0->retina-face) (3.1.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown>=3.10.1->retina-face) (2.8)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown>=3.10.1->retina-face) (1.7.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow>=1.9.0->retina-face) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow>=1.9.0->retina-face) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow>=1.9.0->retina-face) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=1.9.0->retina-face) (0.1.2)\n",
            "Downloading retina_face-0.0.17-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: retina-face\n",
            "Successfully installed retina-face-0.0.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "qxYedmPzr3B6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from glob import glob\n",
        "import json"
      ],
      "metadata": {
        "id": "ZJQFcQ8G63IQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from retinaface import RetinaFace"
      ],
      "metadata": {
        "id": "KG2RciPc9gEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keyframe Extraction"
      ],
      "metadata": {
        "id": "GsG4nS18smbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_keyframes(video_path, threshold=10.0, metadata_file=\"keyframes_metadata.json\"):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error: Could not open {video_path}\")\n",
        "        return []\n",
        "\n",
        "    keyframes = []\n",
        "    video_name = os.path.basename(video_path)\n",
        "    metadata = {\"video_name\": video_name, \"keyframes\": []}\n",
        "\n",
        "    ret, prev_frame_bgr = cap.read()\n",
        "    if not ret:\n",
        "        print(f\"Error: Could not read first frame of {video_path}\")\n",
        "        return []\n",
        "\n",
        "    prev_frame_gray = cv2.cvtColor(prev_frame_bgr, cv2.COLOR_BGR2GRAY)\n",
        "    keyframes.append((0, prev_frame_bgr))\n",
        "    metadata[\"keyframes\"].append({\"frame_index\": 0, \"motion_score\": None})\n",
        "\n",
        "    frame_idx = 1\n",
        "    while True:\n",
        "        ret, curr_frame_bgr = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        curr_frame_gray = cv2.cvtColor(curr_frame_bgr, cv2.COLOR_BGR2GRAY)\n",
        "        motion_score = get_motion_score(prev_frame_gray, curr_frame_gray)\n",
        "\n",
        "        if motion_score > threshold:\n",
        "            keyframes.append((frame_idx, curr_frame_bgr))\n",
        "            metadata[\"keyframes\"].append({\n",
        "                \"frame_index\": frame_idx,\n",
        "                \"motion_score\": float(motion_score)\n",
        "            })\n",
        "            prev_frame_gray = curr_frame_gray\n",
        "\n",
        "        frame_idx += 1\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    if os.path.exists(metadata_file):\n",
        "        with open(metadata_file, \"r\") as f:\n",
        "            existing = json.load(f)\n",
        "    else:\n",
        "        existing = {}\n",
        "\n",
        "    existing[video_name] = metadata[\"keyframes\"]\n",
        "\n",
        "    with open(metadata_file, \"w\") as f:\n",
        "        json.dump(existing, f, indent=4)\n",
        "\n",
        "    print(f\"✅ Extracted {len(keyframes)} keyframes, metadata updated in {metadata_file}\")\n",
        "    return keyframes"
      ],
      "metadata": {
        "id": "cFo8n-Pc-Idw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_motion_score(frame1, frame2, kernel=np.ones((9,9), dtype=np.uint8)):\n",
        "    frame_diff = cv2.subtract(frame2, frame1)\n",
        "    frame_diff = cv2.medianBlur(frame_diff, 3)\n",
        "    mask = cv2.adaptiveThreshold(frame_diff, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                                 cv2.THRESH_BINARY_INV, 11, 3)\n",
        "    mask = cv2.medianBlur(mask, 3)\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
        "    motion_score = np.sum(mask) / (mask.shape[0] * mask.shape[1])\n",
        "    return motion_score\n",
        "\n",
        "def alternative_algorithm(video_path, skip_frames=10):\n",
        "    \"\"\"\n",
        "    Extract frames from a video by skipping a fixed number of frames.\n",
        "    \"\"\"\n",
        "    print(f\"Applying frame-skipping algorithm to {video_path}\")\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    keyframes = []\n",
        "    frame_idx = 0\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        if frame_idx % skip_frames == 0:\n",
        "            keyframes.append((frame_idx, frame))\n",
        "\n",
        "        frame_idx += 1\n",
        "\n",
        "    cap.release()\n",
        "    print(f\"✅ Extracted {len(keyframes)} frames by skipping {skip_frames} frames each time.\")\n",
        "    return keyframes"
      ],
      "metadata": {
        "id": "WwmsgJwx-jCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUi9xGZ-6aDK"
      },
      "outputs": [],
      "source": [
        "def process_saved_frames(frames_dir=\"All_Frames\", faces_dir=\"Faces_Extracted\", metadata_file=\"faces_metadata.json\"):\n",
        "    os.makedirs(faces_dir, exist_ok=True)\n",
        "    frame_folders = glob(os.path.join(frames_dir, \"*\"))\n",
        "\n",
        "    if os.path.exists(metadata_file):\n",
        "        with open(metadata_file, \"r\") as f:\n",
        "            all_metadata = json.load(f)\n",
        "    else:\n",
        "        all_metadata = {}\n",
        "\n",
        "    for folder in frame_folders:\n",
        "        print(f\"Processing frames in {folder} ...\")\n",
        "        video_name = os.path.basename(folder)\n",
        "        video_faces_dir = os.path.join(faces_dir, video_name)\n",
        "        os.makedirs(video_faces_dir, exist_ok=True)\n",
        "\n",
        "        video_metadata = []\n",
        "\n",
        "        frame_files = sorted(\n",
        "            glob(os.path.join(folder, \"*.png\")) +\n",
        "            glob(os.path.join(folder, \"*.jpg\")) +\n",
        "            glob(os.path.join(folder, \"*.jpeg\"))\n",
        "        )\n",
        "\n",
        "        print(f\"Found {len(frame_files)} frames in {video_name}\")\n",
        "        for f_idx, frame_file in enumerate(frame_files):\n",
        "            frame = cv2.imread(frame_file)\n",
        "            if frame is None:\n",
        "                continue\n",
        "\n",
        "            frame_data = {\n",
        "                \"frame_index\": f_idx,\n",
        "                \"frame_path\": frame_file,\n",
        "                \"faces\": []\n",
        "            }\n",
        "\n",
        "            faces = detect_and_crop_faces(frame)\n",
        "            for idx, (face_img, bbox) in enumerate(faces):\n",
        "                ext = os.path.splitext(frame_file)[1]\n",
        "                face_file = os.path.join(video_faces_dir, f\"{video_name}_frame{f_idx:05d}_face{idx}{ext}\")\n",
        "                cv2.imwrite(face_file, face_img)\n",
        "\n",
        "                face_metadata = {\n",
        "                    \"face_index\": idx,\n",
        "                    \"bbox\": bbox,\n",
        "                    \"cropped_face_path\": face_file\n",
        "                }\n",
        "                frame_data[\"faces\"].append(face_metadata)\n",
        "\n",
        "            if frame_data[\"faces\"]:\n",
        "                video_metadata.append(frame_data)\n",
        "\n",
        "        all_metadata[video_name] = video_metadata\n",
        "        print(f\"Processed {len(frame_files)} frames for {video_name}\")\n",
        "\n",
        "    with open(metadata_file, \"w\") as f:\n",
        "        json.dump(all_metadata, f, indent=4)\n",
        "\n",
        "    print(f\"✅ Face detection complete! Metadata updated in {metadata_file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Redirect stdout"
      ],
      "metadata": {
        "id": "XTFsVBb7vS_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import contextlib\n",
        "\n",
        "@contextlib.contextmanager\n",
        "def suppress_stdout():\n",
        "    with open(os.devnull, \"w\") as devnull:\n",
        "        old_stdout = sys.stdout\n",
        "        sys.stdout = devnull\n",
        "        try:\n",
        "            yield\n",
        "        finally:\n",
        "            sys.stdout = old_stdout"
      ],
      "metadata": {
        "id": "jAg7CGi0vTUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Face Detection"
      ],
      "metadata": {
        "id": "LSQj2z9JsxWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_face_square(img, face, margin_ratio=0.2, target_size=(112, 112)):\n",
        "    h, w = img.shape[:2]\n",
        "    x1, y1, x2, y2 = face[\"facial_area\"]\n",
        "\n",
        "    bw = x2 - x1\n",
        "    bh = y2 - y1\n",
        "    margin_x = int(bw * margin_ratio)\n",
        "    margin_y = int(bh * margin_ratio)\n",
        "\n",
        "    x1 = max(0, x1 - margin_x)\n",
        "    y1 = max(0, y1 - margin_y)\n",
        "    x2 = min(w, x2 + margin_x)\n",
        "    y2 = min(h, y2 + margin_y)\n",
        "\n",
        "    crop_w = x2 - x1\n",
        "    crop_h = y2 - y1\n",
        "    if crop_w > crop_h:\n",
        "        diff = crop_w - crop_h\n",
        "        expand_top = diff // 2\n",
        "        expand_bottom = diff - expand_top\n",
        "        if y1 - expand_top >= 0 and y2 + expand_bottom <= h:\n",
        "            y1 -= expand_top\n",
        "            y2 += expand_bottom\n",
        "        else:\n",
        "            x1 += diff // 2\n",
        "            x2 -= (diff - diff // 2)\n",
        "    elif crop_h > crop_w:\n",
        "        diff = crop_h - crop_w\n",
        "        expand_left = diff // 2\n",
        "        expand_right = diff - expand_left\n",
        "        if x1 - expand_left >= 0 and x2 + expand_right <= w:\n",
        "            x1 -= expand_left\n",
        "            x2 += expand_right\n",
        "        else:\n",
        "            y1 += diff // 2\n",
        "            y2 -= (diff - diff // 2)\n",
        "\n",
        "    x1, x2 = max(0, x1), min(w, x2)\n",
        "    y1, y2 = max(0, y1), min(h, y2)\n",
        "\n",
        "    cropped_face = img[y1:y2, x1:x2]\n",
        "\n",
        "    if cropped_face.size == 0:\n",
        "        return None, None\n",
        "\n",
        "    resized_face = cv2.resize(cropped_face, target_size, interpolation=cv2.INTER_AREA)\n",
        "    updated_bbox = [int(x1), int(y1), int(x2), int(y2)]\n",
        "    return resized_face, updated_bbox"
      ],
      "metadata": {
        "id": "AKflbppKszs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_and_crop_faces(frame, margin_ratio=0.2, target_size=(112,112)):\n",
        "    with suppress_stdout():\n",
        "        faces_detected = RetinaFace.detect_faces(frame)\n",
        "\n",
        "    cropped_faces = []\n",
        "\n",
        "    if not isinstance(faces_detected, dict) or len(faces_detected) == 0:\n",
        "        return []\n",
        "\n",
        "    for key, face_data in faces_detected.items():\n",
        "        cropped_face, updated_bbox = process_face_square(frame, face_data, margin_ratio, target_size)\n",
        "        if cropped_face is None or updated_bbox is None:\n",
        "            continue\n",
        "\n",
        "        cropped_faces.append((cropped_face, updated_bbox))\n",
        "\n",
        "    return cropped_faces"
      ],
      "metadata": {
        "id": "Xy-eLADts25S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Directory Setup"
      ],
      "metadata": {
        "id": "yvn27ZYotani"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video_directory = \"Videos\"\n",
        "\n",
        "output_dir = \"Processed_Video_Frames\"\n",
        "cropped_faces_directory = \"Faces_Extracted_RetinaFace\"\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "os.makedirs(cropped_faces_directory, exist_ok=True)"
      ],
      "metadata": {
        "id": "hEJJLPl57hn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Process Video Keyframes"
      ],
      "metadata": {
        "id": "5M1cL2y6tFY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video_files = glob(os.path.join(video_directory, \"*.mp4\"))\n",
        "print(f\"Found {len(video_files)} videos\")\n",
        "\n",
        "duration_threshold_sec = 60"
      ],
      "metadata": {
        "id": "M9G2ZP7otAnj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e412e200-4df8-4c6e-8716-6bf3bb52f635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9 videos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for video_path in video_files:\n",
        "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
        "    save_path = os.path.join(output_dir, video_name)\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "    # Check video duration\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "    duration_sec = frame_count / fps if fps > 0 else 0\n",
        "    cap.release()\n",
        "\n",
        "    print(f\"\\n\\nProcessing {video_name} ... Duration: {duration_sec:.2f}s\")\n",
        "\n",
        "    if duration_sec < duration_threshold_sec:\n",
        "        keyframes = alternative_algorithm(video_path)\n",
        "    else:\n",
        "        keyframes = extract_keyframes(video_path, threshold=28.0)\n",
        "\n",
        "    for i, (idx, frame) in enumerate(keyframes):\n",
        "        frame_path = os.path.join(save_path, f\"{video_name}_keyframe_{i}_frame{idx}.png\")\n",
        "        cv2.imwrite(frame_path, frame)\n",
        "\n",
        "print(\"\\n\\n✅ Keyframe extraction complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJIb8jJ17Bkx",
        "outputId": "c61440bf-1a61-4ede-f960-96ac4306bd7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Processing tourists ... Duration: 2.00s\n",
            "Applying frame-skipping algorithm to Videos/tourists.mp4\n",
            "✅ Extracted 5 frames by skipping 10 frames each time.\n",
            "\n",
            "\n",
            "Processing F3 ... Duration: 336.40s\n",
            "✅ Extracted 503 keyframes, metadata updated in keyframes_metadata.json\n",
            "\n",
            "\n",
            "Processing S2 ... Duration: 78.17s\n",
            "✅ Extracted 1302 keyframes, metadata updated in keyframes_metadata.json\n",
            "\n",
            "\n",
            "Processing S1_N1 ... Duration: 60.08s\n",
            "✅ Extracted 2 keyframes, metadata updated in keyframes_metadata.json\n",
            "\n",
            "\n",
            "Processing F2 ... Duration: 12.71s\n",
            "Applying frame-skipping algorithm to Videos/F2.mp4\n",
            "✅ Extracted 31 frames by skipping 10 frames each time.\n",
            "\n",
            "\n",
            "Processing F1 ... Duration: 15.38s\n",
            "Applying frame-skipping algorithm to Videos/F1.mp4\n",
            "✅ Extracted 37 frames by skipping 10 frames each time.\n",
            "\n",
            "\n",
            "Processing F4 ... Duration: 581.73s\n",
            "✅ Extracted 1270 keyframes, metadata updated in keyframes_metadata.json\n",
            "\n",
            "\n",
            "Processing S3 ... Duration: 81.90s\n",
            "✅ Extracted 16 keyframes, metadata updated in keyframes_metadata.json\n",
            "\n",
            "\n",
            "Processing S4 ... Duration: 21.73s\n",
            "Applying frame-skipping algorithm to Videos/S4.mp4\n",
            "✅ Extracted 65 frames by skipping 10 frames each time.\n",
            "\n",
            "\n",
            "✅ Keyframe extraction complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Process saved frames for face detetction"
      ],
      "metadata": {
        "id": "pPmK0xFJtLbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "process_saved_frames(output_dir, cropped_faces_directory)\n",
        "\n",
        "print(\"✅ Detection and Cropping complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsLOGhH87d8N",
        "outputId": "9b564427-5402-4641-ba14-4cb3d4f19499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing frames in Processed_Video_Frames/S1_N1 ...\n",
            "Found 2 frames in S1_N1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/serengil/deepface_models/releases/download/v1.0/retinaface.h5\n",
            "To: /root/.deepface/weights/retinaface.h5\n",
            "100%|██████████| 119M/119M [00:01<00:00, 74.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 2 frames for S1_N1\n",
            "Processing frames in Processed_Video_Frames/F3 ...\n",
            "Found 503 frames in F3\n",
            "Processed 503 frames for F3\n",
            "Processing frames in Processed_Video_Frames/S3 ...\n",
            "Found 16 frames in S3\n",
            "Processed 16 frames for S3\n",
            "Processing frames in Processed_Video_Frames/tourists ...\n",
            "Found 5 frames in tourists\n",
            "Processed 5 frames for tourists\n",
            "Processing frames in Processed_Video_Frames/F2 ...\n",
            "Found 31 frames in F2\n",
            "Processed 31 frames for F2\n",
            "Processing frames in Processed_Video_Frames/F1 ...\n",
            "Found 37 frames in F1\n",
            "Processed 37 frames for F1\n",
            "Processing frames in Processed_Video_Frames/S2 ...\n",
            "Found 1302 frames in S2\n",
            "Processed 1302 frames for S2\n",
            "Processing frames in Processed_Video_Frames/S4 ...\n",
            "Found 65 frames in S4\n",
            "Processed 65 frames for S4\n",
            "Processing frames in Processed_Video_Frames/F4 ...\n",
            "Found 1270 frames in F4\n",
            "Processed 1270 frames for F4\n",
            "✅ Face detection complete! Metadata updated in faces_metadata.json\n",
            "✅ Detection and Cropping complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Checking frames extracted"
      ],
      "metadata": {
        "id": "BuWrItuawR9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from collections import defaultdict\n",
        "from glob import glob\n",
        "\n",
        "all_frames = glob(\"Processed_Video_Frames/*/*.png\") + \\\n",
        "             glob(\"Processed_Video_Frames/*/*.jpg\") + \\\n",
        "             glob(\"Processed_Video_Frames/*/*.jpeg\")\n",
        "\n",
        "print(f\"Total frames stored: {len(all_frames)}\")\n",
        "\n",
        "frame_count_per_video = defaultdict(int)\n",
        "for f in all_frames:\n",
        "    video_name = os.path.basename(os.path.dirname(f))\n",
        "    frame_count_per_video[video_name] += 1\n",
        "\n",
        "print(\"Frames per video:\")\n",
        "for video, count in frame_count_per_video.items():\n",
        "    print(f\"{video}: {count} frames\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fAdfBugBn4G",
        "outputId": "d891c734-a889-4f3a-e3e7-8f340ef98195"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total frames stored: 3231\n",
            "Frames per video:\n",
            "S1_N1: 2 frames\n",
            "F3: 503 frames\n",
            "S3: 16 frames\n",
            "tourists: 5 frames\n",
            "F2: 31 frames\n",
            "F1: 37 frames\n",
            "S2: 1302 frames\n",
            "S4: 65 frames\n",
            "F4: 1270 frames\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Visualization of Frames"
      ],
      "metadata": {
        "id": "NNNUhNAjwbLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import math\n",
        "import os\n",
        "import re\n",
        "\n",
        "def extract_frame_index(path):\n",
        "    \"\"\"Extract numeric frame index from filename\"\"\"\n",
        "    match = re.search(r\"_frame(\\d+)\", os.path.basename(path))\n",
        "    if match:\n",
        "        return int(match.group(1))\n",
        "    return 0\n",
        "\n",
        "def show_video_frames(all_frames, video_name, frames_per_row=10):\n",
        "    video_frames = [f for f in all_frames if os.path.basename(os.path.dirname(f)) == video_name]\n",
        "    total_frames = len(video_frames)\n",
        "    print(f\"Showing {total_frames} frames for {video_name}\")\n",
        "\n",
        "    video_frames = sorted(video_frames, key=extract_frame_index)\n",
        "\n",
        "    rows = math.ceil(total_frames / frames_per_row)\n",
        "    plt.figure(figsize=(20, 2*rows))\n",
        "\n",
        "    for i, frame_file in enumerate(video_frames):\n",
        "        img = cv2.imread(frame_file)\n",
        "        if img is None:\n",
        "            continue\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        plt.subplot(rows, frames_per_row, i+1)\n",
        "        plt.imshow(img_rgb)\n",
        "        plt.title(os.path.basename(frame_file), fontsize=8)\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    plt.suptitle(f\"Frames from video: {video_name}\", fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "for video, count in frame_count_per_video.items():\n",
        "    show_video_frames(all_frames, video)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 20512
        },
        "id": "8k7c19HgBXNy",
        "outputId": "0f189eb1-2691-4811-86ee-e2f76a9c32e7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Visualization of Extracted Faces"
      ],
      "metadata": {
        "id": "psY7pV3GwgnS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import math\n",
        "import os\n",
        "import re\n",
        "from glob import glob\n",
        "\n",
        "def extract_indices(filename):\n",
        "    \"\"\"\n",
        "    Extract frame index and face index from filenames like:\n",
        "    video_frame00012_face1.png\n",
        "    \"\"\"\n",
        "    match = re.search(r\"_frame(\\d+)_face(\\d+)\", filename)\n",
        "    if match:\n",
        "        return int(match.group(1)), int(match.group(2))\n",
        "    return float(\"inf\"), float(\"inf\")\n",
        "\n",
        "def show_images_grid(image_files, title, images_per_row=10):\n",
        "    total = len(image_files)\n",
        "    rows = math.ceil(total / images_per_row)\n",
        "    plt.figure(figsize=(20, 2*rows))\n",
        "\n",
        "    image_files = sorted(image_files, key=lambda f: extract_indices(os.path.basename(f)))\n",
        "\n",
        "    for i, img_file in enumerate(image_files):\n",
        "        img = cv2.imread(img_file)\n",
        "        if img is None:\n",
        "            continue\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        plt.subplot(rows, images_per_row, i+1)\n",
        "        plt.imshow(img_rgb)\n",
        "        plt.title(os.path.basename(img_file), fontsize=8)\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    plt.suptitle(title, fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "faces_dir = \"Faces_Extracted_RetinaFace\"\n",
        "face_folders = glob(os.path.join(faces_dir, \"*\"))\n",
        "\n",
        "for folder in face_folders:\n",
        "    video_name = os.path.basename(folder)\n",
        "    face_files = (\n",
        "        glob(os.path.join(folder, \"*.png\")) +\n",
        "        glob(os.path.join(folder, \"*.jpg\")) +\n",
        "        glob(os.path.join(folder, \"*.jpeg\"))\n",
        "    )\n",
        "    if not face_files:\n",
        "        continue\n",
        "    show_images_grid(face_files, f\"Detected faces from video: {video_name}\", images_per_row=10)"
      ],
      "metadata": {
        "id": "xFdap37mBiy6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 41191
        },
        "outputId": "66aea6f9-ec4d-457b-8042-2b6b9469dcf3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
